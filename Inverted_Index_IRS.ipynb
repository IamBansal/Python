{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAqHJWfgeIkTAM2gLHIts3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamBansal/Python/blob/main/Inverted_Index_IRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverted Index Algorithm - IRS lab 2"
      ],
      "metadata": {
        "id": "vTWr86gG0_Ys"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCgb09ydvMRi",
        "outputId": "3aba400b-993d-4834-a5fe-7c40e4a986bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of lines in file is:  4\n",
            "\n",
            " ['This is the first word.\\n', 'This is the second text, Hello! How are you?\\n', 'This is the third, this is it now.\\n', 'My name is Akshat Bansal']\n",
            "\n",
            " This is the first word \n",
            "This is the second text  Hello  How are you \n",
            "This is the third  this is it now \n",
            "My name is Akshat Bansal\n",
            "\n",
            " this is the first word \n",
            "this is the second text  hello  how are you \n",
            "this is the third  this is it now \n",
            "my name is akshat bansal\n",
            "\n",
            " ['this', 'is', 'the', 'first', 'word', 'this', 'is', 'the', 'second', 'text', 'hello', 'how', 'are', 'you', 'this', 'is', 'the', 'third', 'this', 'is', 'it', 'now', 'my', 'name', 'is', 'akshat', 'bansal']\n",
            "\n",
            " ['word', 'text', 'akshat', 'bansal']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'word': [1], 'text': [2], 'akshat': [4], 'bansal': [4]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "#To open and read the file\n",
        "file = open('/content/file.txt', encoding='utf8')\n",
        "read = file.read()\n",
        "file.seek(0)\n",
        "read\n",
        "\n",
        "#To print the number of lines in the file\n",
        "line = 1\n",
        "for word in read:\n",
        "\tif word == '\\n':\n",
        "\t\tline += 1\n",
        "print(\"\\nNumber of lines in file is: \", line)\n",
        "\n",
        "#Create a list to store each line in array as an element.\n",
        "array = []\n",
        "for i in range(line):\n",
        "\tarray.append(file.readline())\n",
        "\n",
        "print('\\n', array)\n",
        "\n",
        "#Remove punctuation marks from lines.\n",
        "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "for ele in read:\n",
        "\tif ele in punc:\n",
        "\t\tread = read.replace(ele, \" \")\n",
        "\t\t\n",
        "print('\\n',read)\n",
        "\n",
        "#Convert all in lowercase\n",
        "read=read.lower()\t\t\t\t\n",
        "print('\\n',read)\n",
        "\n",
        "#Tokenize all the content\n",
        "for i in range(1):\n",
        "\ttext_tokens = word_tokenize(read)\n",
        "print('\\n',text_tokens)\n",
        "\n",
        "#Removing the stopwords\n",
        "tokens_without_sw = [\n",
        "\tword for word in text_tokens if not word in stopwords.words()]\n",
        "\n",
        "print('\\n',tokens_without_sw)\n",
        "\n",
        "#Checking for the stopwords in the respective line\n",
        "dict = {}\n",
        "\n",
        "for i in range(line):\n",
        "\tcheck = array[i].lower()\n",
        "\tfor item in tokens_without_sw:\n",
        "\n",
        "\t\tif item in check:\n",
        "\t\t\tif item not in dict:\n",
        "\t\t\t\tdict[item] = []\n",
        "\n",
        "\t\t\tif item in dict:\n",
        "\t\t\t\tdict[item].append(i+1)\n",
        "\n",
        "dict"
      ]
    }
  ]
}